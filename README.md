# Explicit belief and LLMs
This is the repository that accompanies the following paper:

- Pan, D., and Bergen, B. (2025). Are explicit belief representations necessary? A comparison between Large Language Models and Bayesian probabilistic models. In Proceedings of the 2025 Annual Conference of the Nations of the Americas Chapter of the ACL.

## General information
The need for explicit representations of mental states to model human pragmatic inferences has long been a subject of debate in the field of pragmatics. We conducted two experiments to test 1) whether Large Language Models (LLMs) are sensitive to factors that modulate projection inferences and 2) whether Bayesian probabilistic models or LLMs better capture human performances. The tasks are similar to those in Degen & Tonhauser (2021), which include:

Task1: prior belief judgement

Task2: projection inference with controlled priors and different predicates

## Structure of this repository
- `analysis`: R files for the graphs and main analyses
- `data`: output files of LLMs and human behavior data
- `stimuli`: input files for LLMs